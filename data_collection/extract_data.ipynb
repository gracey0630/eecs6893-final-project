{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37128b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "from datetime import datetime\n",
    "import math\n",
    "import requests\n",
    "from pathlib import Path\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b42d7f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read only - don't need to authenticate\n",
    "reddit = praw.Reddit(\n",
    "    client_id=\"JT_iiB-NFwFyoknGwv5fYA\",\n",
    "    client_secret=\"aVY6bitDc5BS8j4LX1cWusWjlgCaVQ\",\n",
    "    user_agent=\"mac:eecs6893Project:v1.0 (by u/Superb-Cap8523)\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44de98a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subreddit names\n",
    "DALLE_SUBR = \"dalle2\"\n",
    "MIDJ_SUBR = \"midjourney\"\n",
    "AIART_SUBR = \"aiArt\"\n",
    "subreddits = [DALLE_SUBR, MIDJ_SUBR, AIART_SUBR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05b346d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flair for each subreddit we are scrapping\n",
    "flair_dict = {MIDJ_SUBR: set(['AI Showcase - Midjourney']),\n",
    "              DALLE_SUBR: set(['DALL·E 2', 'DALL·E 3']),\n",
    "              AIART_SUBR: set(['Image -  I used x/ai\\'s \"Imagine Image and Video Generator.\"  ',\n",
    "                            'Image - Bing Image Creator :a2:',\n",
    "                            'Image - BudgetPixel',\n",
    "                            'Image - BudgetPixel AI',\n",
    "                            'Image - ChatGPT :a2:',\n",
    "                            'Image - CivitAI\\xa0:a2:',\n",
    "                            'Image - ComfyUI',\n",
    "                            'Image - Custom',\n",
    "                            'Image - DALL E 3 :a2:',\n",
    "                            'Image - DeepAI',\n",
    "                            'Image - Eggie.ai',\n",
    "                            'Image - Etana',\n",
    "                            'Image - FLUX :a2:',\n",
    "                            'Image - Gemini',\n",
    "                            'Image - Google Gemini :a2:',\n",
    "                            'Image - Google Imagen',\n",
    "                            'Image - Grok',\n",
    "                            'Image - Illustrious',\n",
    "                            'Image - ImageFX.',\n",
    "                            'Image - Komiko',\n",
    "                            'Image - Leonardo.ai :a2:',\n",
    "                            'Image - Mage.space',\n",
    "                            'Image - Meta AI  :a2:',\n",
    "                            'Image - Microsoft Copilot',\n",
    "                            'Image - Midjourney :a2:',\n",
    "                            'Image - MuleRun Agent',\n",
    "                            'Image - MuleRun Halloween Costume Agent',\n",
    "                            'Image - Nightcafe :a2:',\n",
    "                            'Image - Other: Aierone',\n",
    "                            'Image - Other: ComfyUI',\n",
    "                            'Image - Other: Flat AI',\n",
    "                            'Image - Other: Grok Imagine',\n",
    "                            'Image - Other: Hailou Ai',\n",
    "                            'Image - Other: Moescape [Illustrious]',\n",
    "                            'Image - Other: MuleRunAI',\n",
    "                            'Image - Other: NovelAI',\n",
    "                            'Image - Other: PixNova AI',\n",
    "                            'Image - Other: Please edit, or your post may be deleted.',\n",
    "                            'Image - Other: Seedream 4.0',\n",
    "                            'Image - Other: Wan/Grok/Meta/Nano Banana/Qwen',\n",
    "                            'Image - Other: Whisk',\n",
    "                            'Image - Qwen',\n",
    "                            'Image - Seedream',\n",
    "                            'Image - Seedream 1.0',\n",
    "                            'Image - Sogni AI',\n",
    "                            'Image - SoraAI :a2:',\n",
    "                            'Image - Stable Diffusion + Manual Editing',\n",
    "                            'Image - Stable Diffusion :a2:',\n",
    "                            'Image - String AI',\n",
    "                            'Image - VQGAN+clip',\n",
    "                            'Image - Wan',\n",
    "                            'Image - Whisk',\n",
    "                            'Image - etana'])\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2f832e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r/dalle2:\n",
      "oldest: 2023-09-30 07:29:43\n",
      "newest: 2025-11-18 05:04:10\n",
      "time span: 779 days\n",
      "approximate amount of posts/day: 1.2836970474967908 posts/day (all the posts)\n",
      "\n",
      "r/midjourney:\n",
      "oldest: 2025-10-22 11:34:36\n",
      "newest: 2025-11-20 10:31:35\n",
      "time span: 28 days\n",
      "approximate amount of posts/day: 35.714285714285715 posts/day (all the posts)\n",
      "\n",
      "r/aiArt:\n",
      "oldest: 2025-11-10 14:33:39\n",
      "newest: 2025-11-20 10:32:22\n",
      "time span: 9 days\n",
      "approximate amount of posts/day: 111.11111111111111 posts/day (all the posts)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check the timeframe of 1000 posts so that we can get how many posts to expect to scrape per day later\n",
    "# but note that this isn't even filtered, so its an overestimate\n",
    "\n",
    "for sub_name in subreddits:\n",
    "    subreddit = reddit.subreddit(sub_name)\n",
    "    posts = list(subreddit.new(limit=1000))\n",
    "    \n",
    "    newest = datetime.fromtimestamp(posts[0].created_utc)\n",
    "    oldest = datetime.fromtimestamp(posts[-1].created_utc)\n",
    "    time_span = newest - oldest\n",
    "    \n",
    "    total_seconds = time_span.total_seconds()\n",
    "    hours = int(total_seconds // 3600)\n",
    "    minutes = int((total_seconds % 3600) // 60)\n",
    "\n",
    "    print(f\"r/{sub_name}:\")\n",
    "    print(f\"oldest: {oldest}\")\n",
    "    print(f\"newest: {newest}\")\n",
    "    print(f\"time span: {time_span.days} days\")\n",
    "    ppd = 1000/time_span.days\n",
    "    print(f\"approximate amount of posts/day: {ppd} posts/day (all the posts)\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b255df92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b84d3d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get and save images from the given subreddit and flair INITIALLY\n",
    "#! ONLY RUN THIS ONCE\n",
    "def save_imgs_from_subreddit_init(subr, flair):\n",
    "    # save metadata for aiArt\n",
    "    metadata = {}\n",
    "\n",
    "    subreddit = reddit.subreddit(subr)\n",
    "    img_cnt = 0\n",
    "\n",
    "    for submission in subreddit.new(limit=1000):\n",
    "\n",
    "        # only get flairs related to images\n",
    "        if submission.link_flair_text not in flair:\n",
    "            continue\n",
    "\n",
    "        # check if the url is an image\n",
    "        if not submission.url.endswith(('.jpg', '.jpeg', '.png')):\n",
    "            continue\n",
    "\n",
    "        # skip nsfw imgs\n",
    "        if submission.over_18:\n",
    "            continue\n",
    "\n",
    "        # get file extension\n",
    "        file_extension = submission.url.split(sep=\".\")[-1].lower()\n",
    "\n",
    "        # get folder for subreddit\n",
    "        image_dir = Path(f\"data/{subr}\")\n",
    "        image_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "        # download the image to inital data folder\n",
    "        try:\n",
    "            response = requests.get(submission.url, timeout=10)\n",
    "            filename = image_dir / f\"img_{subr}_{submission.id}.{file_extension}\"\n",
    "\n",
    "            with open(filename, \"wb\") as f:\n",
    "                f.write(response.content)\n",
    "\n",
    "            img_cnt +=1\n",
    "\n",
    "            # only the aiArt subreddit needs metadata\n",
    "            if subr != MIDJ_SUBR:\n",
    "                metadata[str(filename)] = {'flair': submission.link_flair_text,\n",
    "                                      'url': submission.url}\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"error {e} for {submission.url}\")\n",
    "\n",
    "    # end of for loop, if its aiArt, need to save the metadata also to the folder\n",
    "    if subr != MIDJ_SUBR:\n",
    "        metadata_filepath = f\"{image_dir}/metadata.json\"\n",
    "        with open(metadata_filepath, \"w\") as json_file:\n",
    "            json.dump(metadata, json_file, indent=4)\n",
    "\n",
    "    print(f\"for subreddit {subr}, saved {img_cnt} images from past 1000 posts\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b4e731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for subreddit dalle2, saved 291 images from past 1000 posts\n",
      "\n",
      "for subreddit midjourney, saved 192 images from past 1000 posts\n",
      "\n",
      "for subreddit aiArt, saved 482 images from past 1000 posts\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# save images from past 1k post on 11/9 for all subreddits\n",
    "for subr in subreddits:\n",
    "    save_imgs_from_subreddit_init(subr, flair_dict[subr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "27a41851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for r/dalle2, 0.379400260756193 image posts per day\n",
      "for r/midjourney, 6.620689655172414 image posts per day\n",
      "for r/aiArt, 53.55555555555556 image posts per day\n"
     ]
    }
   ],
   "source": [
    "# number of image post per day\n",
    "filtered_ppd = np.array([291, 192, 482])/np.array([767, 29, 9])\n",
    "for subreddit, ppd in zip(subreddits, filtered_ppd):\n",
    "    print(f\"for r/{subreddit}, {ppd} image posts per day\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea27154a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eecs6893-final-proj-venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
